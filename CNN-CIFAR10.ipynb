{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set transforms  with Normalize of  0.5 for mean and 0.5 for std\n",
    "\n",
    "#download th CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a dictnary  that have train and test each have DataLoader\n",
    "# we use DataLoader to make itrator reading the reded by data and batch them with shuffle\n",
    "\n",
    "#dictanry for size of each data  train and val size is for all not for itrator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extand the Module form nn to build flaten class that\n",
    "#use forward to  make dim  from 2d  to 1  \n",
    "#where view is  like reshape  and .size() is like using .shape the zero index\n",
    "#is the first dim in sgape and -1 take care of  uncomplated dim\n",
    "\n",
    "#build model using the easist way wiith Sequential and OrderedDict , Conv2d is convlution layer\n",
    "#MaxPool2d is pooling layer ,  Linear is = w*x + b \n",
    "\n",
    "#show the strcture o the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#turn off  requires_grad for all parameters in the model\n",
    "\n",
    "# make i classifier use Sequential and OrderedDict \n",
    "#we will use logtis of the softmax  that mean we take over dim is one\n",
    "\n",
    "\n",
    "#set loss  crtria since we take logsoftmax   the  loss is Nigtive Loge likliy hood loss \n",
    "\n",
    "\n",
    "# optimizer Observe that all parameters are being optimized and the lr for our optim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check if cuda is available from torch to set device to cuda or to cpu if not\n",
    "\n",
    "# set epochs number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# llop over epochs \n",
    "    \n",
    "    #loop over phases [train,val]\n",
    "    \n",
    "        #rembber if phase is valdation we set model to eval() mode\n",
    "        \n",
    "        #Eelse we ste it to train() mode\n",
    "        \n",
    "        # we transfer model to(divce) already \n",
    "        # we check this var model.to(device)\n",
    "        \n",
    "        # also we need some var  to be acculmator for loss and coorect predaction\n",
    "        # this start as zero and accumlated then each new epoch return to zero\n",
    "        \n",
    "        #loop over dataloader dictnary handler is phase and get data and labels\n",
    "        \n",
    "            #set both data and laebls to go to device \n",
    "            \n",
    "            \n",
    "            # clear the  optimizer with zero_grad()\n",
    "            \n",
    "            #set the torch  grad to enabled() with  thus  phase  is train\n",
    "            \n",
    "                #calclute the output from the model\n",
    "                \n",
    "                #get top 1  max from output to get prediction tuple \n",
    "                \n",
    "                #get loss by the ctriria you set  using output and  real labes\n",
    "                \n",
    "                #if we in train phase do backward() calcultion for the loss\n",
    "                #and step the optimizer\n",
    "                \n",
    "\n",
    "            #acculmate the loss by add to it item loss  * batch of itrator its the size \n",
    "            #of zeo index from our data geted by itrator loadr\n",
    "            \n",
    "            #accoumlat the coorect add to it sum of all data from label that eql the predaction\n",
    "            \n",
    "        #epoch loss is the accumlated / datasize dictanry for handler of hase\n",
    "        \n",
    "        # epoch acc is the accumalted correct  /  datasize dictanry for handler of hase\n",
    "\n",
    "        #print  the oss and acc and phase and epoci num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
